{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, Reshape\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Today, all Indians in the country and also abroad are celebrating the festival of independence. On this day of sacred festival of independence, the prime servant of India extends greetings to all dear countrymen.\n",
    "\n",
    "I am present amidst you not as the Prime Minister, but as the Prime Servant. The freedom struggle was fought for so many years, so many generations laid down their lives, innumerable people sacrificed their lives and youth, spent their entire lives behind bars. Today, I pay my respect, greetings and homage to all those who laid their lives for the country's independence.\n",
    "\n",
    "I also pay my respects to the crores of citizens of this country on the pious occasion of India's independence, and recall all those martyrs who had laid down their lives in India's struggle for freedom. The day of independence is a festival when we take a solemn pledge of working for the welfare of mother India, and also for the welfare of the poor, oppressed, dalits, the exploited & the backward people of our country.\n",
    "\n",
    "My dear countrymen, a national festival is an occasion to refine and rebuild the national character. This National festival inspires us to resolve ourselves to lead a life where our character gets refined further, to dedicate ourselves to the nation and our every activity is linked to the interest of the nation and only then this festival of freedom can be a festival of inspiration to take India to newer heights. My dear countrymen, this nation has neither been built by political leaders nor by rulers nor by governments. This nation has been built by our farmers, our workers, our mothers and sisters, our youth. The country has reached here today because of generation to generation rigours undertaken by our sages, our saints, our maestros, our teachers, our scientists and social workers. These great people and these great generations, who had worked for the country throughout their lives, deserve our deepest respect. This is the beauty of India's Constitution, this is its capability which has made it possible that today a boy from small town, a poor family has got the opportunity to pay homage to the tri-colour of India at the ramparts of \n",
    "Lal Quila (Red Fort). This is the strength of India's democracy. This is an invaluable legacy which we have inherited from our architects of the constitution. I pay my respects to those architects of the constitution of India today.\n",
    "\n",
    "Brothers and sisters, today if we have reached here after independence, it is because of the contribution of all the Prime Ministers, all the governments and even the governments of all the States. I want to express my feelings of respect and gratitude to all those previous governments and ex-Prime Ministers who have endeavoured to take our present day India to such heights and who have added to the country's glory.\n",
    "\n",
    "This country has been built on such foundation of ancient cultural heritage, where we were told of only one\n",
    "mantra during \n",
    "Vedic period, which is indicative of our work culture, which we have learnt, we have memorized \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = []\n",
    "for sentence in corpus.split('\\n'):\n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "    for i in range(1, len(tokenized_sentence)):\n",
    "        input.append(tokenized_sentence[:i+1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(x) for x in input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_seq = pad_sequences(input, maxlen=max_len, padding=\"pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,  11,   8],\n",
       "       [  0,   0,   0, ...,  11,   8,  84],\n",
       "       [  0,   0,   0, ...,   8,  84,  46],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  21, 211,  19],\n",
       "       [  0,   0,   0, ..., 211,  19,  21],\n",
       "       [  0,   0,   0, ...,  19,  21, 212]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padded_seq[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = padded_seq[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 194)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=213, output_dim=100, input_length=max_len-1))\n",
    "model.add(LSTM(units=150))\n",
    "model.add(Dense(units=213, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_15 (Embedding)    (None, 194, 100)          21300     \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 150)               150600    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 213)               32163     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 204,063\n",
      "Trainable params: 204,063\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 36s 334ms/step - loss: 5.2382 - accuracy: 0.0470 - val_loss: 5.2576 - val_accuracy: 0.0980\n",
      "Epoch 2/70\n",
      "101/101 [==============================] - 34s 336ms/step - loss: 4.9032 - accuracy: 0.0569 - val_loss: 5.3879 - val_accuracy: 0.0980\n",
      "Epoch 3/70\n",
      "101/101 [==============================] - 33s 327ms/step - loss: 4.7692 - accuracy: 0.0569 - val_loss: 5.4205 - val_accuracy: 0.0980\n",
      "Epoch 4/70\n",
      "101/101 [==============================] - 33s 325ms/step - loss: 4.6078 - accuracy: 0.0842 - val_loss: 5.6067 - val_accuracy: 0.0784\n",
      "Epoch 5/70\n",
      "101/101 [==============================] - 33s 323ms/step - loss: 4.3324 - accuracy: 0.0990 - val_loss: 5.6049 - val_accuracy: 0.0882\n",
      "Epoch 6/70\n",
      "101/101 [==============================] - 32s 319ms/step - loss: 3.9084 - accuracy: 0.1485 - val_loss: 5.5969 - val_accuracy: 0.0980\n",
      "Epoch 7/70\n",
      "101/101 [==============================] - 41s 408ms/step - loss: 3.4247 - accuracy: 0.2129 - val_loss: 5.7860 - val_accuracy: 0.0980\n",
      "Epoch 8/70\n",
      "101/101 [==============================] - 36s 355ms/step - loss: 2.9261 - accuracy: 0.2748 - val_loss: 5.8295 - val_accuracy: 0.0882\n",
      "Epoch 9/70\n",
      "101/101 [==============================] - 45s 445ms/step - loss: 2.5076 - accuracy: 0.3391 - val_loss: 5.9946 - val_accuracy: 0.0784\n",
      "Epoch 10/70\n",
      "101/101 [==============================] - 44s 434ms/step - loss: 2.0601 - accuracy: 0.4406 - val_loss: 6.2847 - val_accuracy: 0.0588\n",
      "Epoch 11/70\n",
      "101/101 [==============================] - 39s 386ms/step - loss: 1.6992 - accuracy: 0.5495 - val_loss: 6.4753 - val_accuracy: 0.0686\n",
      "Epoch 12/70\n",
      "101/101 [==============================] - 39s 383ms/step - loss: 1.3629 - accuracy: 0.6757 - val_loss: 6.5918 - val_accuracy: 0.0392\n",
      "Epoch 13/70\n",
      "101/101 [==============================] - 38s 381ms/step - loss: 1.0986 - accuracy: 0.7772 - val_loss: 6.7350 - val_accuracy: 0.0588\n",
      "Epoch 14/70\n",
      "101/101 [==============================] - 40s 401ms/step - loss: 0.8728 - accuracy: 0.8490 - val_loss: 6.8667 - val_accuracy: 0.0490\n",
      "Epoch 15/70\n",
      "101/101 [==============================] - 39s 382ms/step - loss: 0.7061 - accuracy: 0.9010 - val_loss: 7.0604 - val_accuracy: 0.0588\n",
      "Epoch 16/70\n",
      "101/101 [==============================] - 48s 472ms/step - loss: 0.5689 - accuracy: 0.9208 - val_loss: 7.2355 - val_accuracy: 0.0490\n",
      "Epoch 17/70\n",
      "101/101 [==============================] - 40s 400ms/step - loss: 0.4591 - accuracy: 0.9604 - val_loss: 7.2865 - val_accuracy: 0.0490\n",
      "Epoch 18/70\n",
      "101/101 [==============================] - 39s 391ms/step - loss: 0.3751 - accuracy: 0.9802 - val_loss: 7.4564 - val_accuracy: 0.0490\n",
      "Epoch 19/70\n",
      "101/101 [==============================] - 40s 397ms/step - loss: 0.3154 - accuracy: 0.9827 - val_loss: 7.4190 - val_accuracy: 0.0490\n",
      "Epoch 20/70\n",
      "101/101 [==============================] - 48s 473ms/step - loss: 0.2601 - accuracy: 0.9851 - val_loss: 7.6133 - val_accuracy: 0.0490\n",
      "Epoch 21/70\n",
      "101/101 [==============================] - 47s 462ms/step - loss: 0.2133 - accuracy: 0.9950 - val_loss: 7.6614 - val_accuracy: 0.0490\n",
      "Epoch 22/70\n",
      "101/101 [==============================] - 40s 398ms/step - loss: 0.1844 - accuracy: 0.9876 - val_loss: 7.7399 - val_accuracy: 0.0490\n",
      "Epoch 23/70\n",
      "101/101 [==============================] - 37s 372ms/step - loss: 0.1543 - accuracy: 0.9926 - val_loss: 7.7612 - val_accuracy: 0.0588\n",
      "Epoch 24/70\n",
      "101/101 [==============================] - 38s 378ms/step - loss: 0.1342 - accuracy: 0.9926 - val_loss: 7.8666 - val_accuracy: 0.0588\n",
      "Epoch 25/70\n",
      "101/101 [==============================] - 33s 321ms/step - loss: 0.1157 - accuracy: 0.9975 - val_loss: 7.8965 - val_accuracy: 0.0490\n",
      "Epoch 26/70\n",
      "101/101 [==============================] - 38s 382ms/step - loss: 0.0992 - accuracy: 1.0000 - val_loss: 7.9748 - val_accuracy: 0.0588\n",
      "Epoch 27/70\n",
      "101/101 [==============================] - 36s 356ms/step - loss: 0.0875 - accuracy: 0.9975 - val_loss: 8.0069 - val_accuracy: 0.0588\n",
      "Epoch 28/70\n",
      "101/101 [==============================] - 35s 352ms/step - loss: 0.0806 - accuracy: 0.9950 - val_loss: 8.0867 - val_accuracy: 0.0588\n",
      "Epoch 29/70\n",
      "101/101 [==============================] - 39s 382ms/step - loss: 0.0805 - accuracy: 0.9950 - val_loss: 8.1329 - val_accuracy: 0.0490\n",
      "Epoch 30/70\n",
      "101/101 [==============================] - 37s 371ms/step - loss: 0.0670 - accuracy: 0.9975 - val_loss: 8.1673 - val_accuracy: 0.0490\n",
      "Epoch 31/70\n",
      "101/101 [==============================] - 40s 400ms/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 8.2109 - val_accuracy: 0.0686\n",
      "Epoch 32/70\n",
      "101/101 [==============================] - 38s 381ms/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 8.2471 - val_accuracy: 0.0588\n",
      "Epoch 33/70\n",
      "101/101 [==============================] - 40s 401ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 8.3012 - val_accuracy: 0.0490\n",
      "Epoch 34/70\n",
      "101/101 [==============================] - 30s 302ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 8.3606 - val_accuracy: 0.0490\n",
      "Epoch 35/70\n",
      "101/101 [==============================] - 25s 245ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 8.3718 - val_accuracy: 0.0588\n",
      "Epoch 36/70\n",
      "101/101 [==============================] - 25s 250ms/step - loss: 0.0509 - accuracy: 0.9926 - val_loss: 8.4036 - val_accuracy: 0.0784\n",
      "Epoch 37/70\n",
      "101/101 [==============================] - 24s 241ms/step - loss: 0.0467 - accuracy: 0.9950 - val_loss: 8.3667 - val_accuracy: 0.0686\n",
      "Epoch 38/70\n",
      "101/101 [==============================] - 25s 252ms/step - loss: 0.0443 - accuracy: 0.9975 - val_loss: 8.4676 - val_accuracy: 0.0490\n",
      "Epoch 39/70\n",
      "101/101 [==============================] - 37s 365ms/step - loss: 0.0306 - accuracy: 0.9975 - val_loss: 8.4869 - val_accuracy: 0.0588\n",
      "Epoch 40/70\n",
      "101/101 [==============================] - 46s 451ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 8.5533 - val_accuracy: 0.0588\n",
      "Epoch 41/70\n",
      "101/101 [==============================] - 40s 396ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 8.6121 - val_accuracy: 0.0588\n",
      "Epoch 42/70\n",
      "101/101 [==============================] - 43s 426ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 8.6001 - val_accuracy: 0.0686\n",
      "Epoch 43/70\n",
      "101/101 [==============================] - 42s 420ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 8.6725 - val_accuracy: 0.0588\n",
      "Epoch 44/70\n",
      "101/101 [==============================] - 43s 423ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 8.6794 - val_accuracy: 0.0490\n",
      "Epoch 45/70\n",
      "101/101 [==============================] - 46s 456ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 8.7092 - val_accuracy: 0.0588\n",
      "Epoch 46/70\n",
      "101/101 [==============================] - 38s 374ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 8.7637 - val_accuracy: 0.0588\n",
      "Epoch 47/70\n",
      "101/101 [==============================] - 31s 312ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 8.7922 - val_accuracy: 0.0588\n",
      "Epoch 48/70\n",
      "101/101 [==============================] - 46s 456ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 8.8278 - val_accuracy: 0.0588\n",
      "Epoch 49/70\n",
      "101/101 [==============================] - 45s 445ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 8.8660 - val_accuracy: 0.0588\n",
      "Epoch 50/70\n",
      "101/101 [==============================] - 45s 443ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 8.8928 - val_accuracy: 0.0588\n",
      "Epoch 51/70\n",
      "101/101 [==============================] - 45s 451ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 8.9189 - val_accuracy: 0.0588\n",
      "Epoch 52/70\n",
      "101/101 [==============================] - 45s 446ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 8.9500 - val_accuracy: 0.0490\n",
      "Epoch 53/70\n",
      "101/101 [==============================] - 45s 445ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 8.9810 - val_accuracy: 0.0588\n",
      "Epoch 54/70\n",
      "101/101 [==============================] - 48s 477ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 9.0036 - val_accuracy: 0.0686\n",
      "Epoch 55/70\n",
      "101/101 [==============================] - 46s 458ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 9.0475 - val_accuracy: 0.0490\n",
      "Epoch 56/70\n",
      "101/101 [==============================] - 45s 448ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 9.0810 - val_accuracy: 0.0588\n",
      "Epoch 57/70\n",
      "101/101 [==============================] - 44s 435ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 9.0916 - val_accuracy: 0.0588\n",
      "Epoch 58/70\n",
      "101/101 [==============================] - 41s 410ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 9.1181 - val_accuracy: 0.0490\n",
      "Epoch 59/70\n",
      "101/101 [==============================] - 48s 477ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 9.1623 - val_accuracy: 0.0588\n",
      "Epoch 60/70\n",
      "101/101 [==============================] - 39s 388ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 9.1825 - val_accuracy: 0.0686\n",
      "Epoch 61/70\n",
      "101/101 [==============================] - 39s 388ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 9.2140 - val_accuracy: 0.0588\n",
      "Epoch 62/70\n",
      "101/101 [==============================] - 40s 392ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 9.2449 - val_accuracy: 0.0588\n",
      "Epoch 63/70\n",
      "101/101 [==============================] - 30s 294ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 9.2794 - val_accuracy: 0.0588\n",
      "Epoch 64/70\n",
      "101/101 [==============================] - 37s 364ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 9.2943 - val_accuracy: 0.0588\n",
      "Epoch 65/70\n",
      "101/101 [==============================] - 39s 386ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 9.3224 - val_accuracy: 0.0588\n",
      "Epoch 66/70\n",
      "101/101 [==============================] - 39s 384ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 9.3632 - val_accuracy: 0.0588\n",
      "Epoch 67/70\n",
      "101/101 [==============================] - 39s 382ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 9.3826 - val_accuracy: 0.0588\n",
      "Epoch 68/70\n",
      "101/101 [==============================] - 27s 263ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 9.4172 - val_accuracy: 0.0686\n",
      "Epoch 69/70\n",
      "101/101 [==============================] - 30s 299ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 9.4428 - val_accuracy: 0.0686\n",
      "Epoch 70/70\n",
      "101/101 [==============================] - 39s 384ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 9.4653 - val_accuracy: 0.0686\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=70, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "india is the country of the prime minister but as the prime servant the freedom struggle was fought for so many generations laid down down innumerable innumerable innumerable their lives in india's struggle for the day of independence is a solemn when we take a solemn solemn working for for the welfare of mother india and also welfare the welfare of the poor oppressed the backward people of our only then of our many our many generations laid down their lives innumerable their lives for the country's independence and youth the country's independence is a solemn a beauty of working for the welfare of mother india and also the welfare of the poor oppressed the backward people of our even the backward people of our fought our many generations who had laid down innumerable innumerable innumerable their lives in india's struggle for the day of independence is a solemn when we take a solemn solemn working for for the welfare of mother india and also welfare the welfare of the poor oppressed the backward people of our only then of our many our many generations laid down their lives innumerable their lives for the country's independence and youth the country's independence is a solemn a beauty of working for the welfare of mother india and also the welfare of the poor oppressed the backward people of our even the backward people of our fought our many generations who had laid down innumerable innumerable innumerable their lives in india's struggle for the day of independence is a solemn when we take a solemn solemn working for for the welfare of mother india and also welfare the welfare of the poor oppressed the backward people of our only then of our many our many generations laid down their lives innumerable their lives for the country's independence and\n"
     ]
    }
   ],
   "source": [
    "text = \"india is the country of\"\n",
    "for i in range(300):\n",
    "    token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "    padded = pad_sequences([token_text], maxlen=max_len-1, padding=\"pre\")\n",
    "    pos = np.argmax(model.predict(padded), axis=1)[0]\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index==pos:\n",
    "            text = text+\" \"+word\n",
    "print(text)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"lstm_text_gen.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tokenizer, open(\"tokenizer.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
